# -*- coding: utf-8 -*-
"""Cancer_cerebro.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XpZYs0t-zYbwWnt1LtFwhbiK6gfCCQgz
"""
# 1) RECOLECCION DE DATOS
#Conectamos con google drive para poder importar las imagenes.
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

#Importamos todas las librerias necesarias para construir el modelo
import os
import re
import matplotlib.pyplot as plt
# %matplotlib inline
import numpy as np
import cv2
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from IPython.display import Image, display
from keras.preprocessing.image import load_img, img_to_array
import pandas as pd

#Indicamos el directorio donde estan todas las imagenes divididas por clases
dirname ="/content/drive/MyDrive/completo"
imgpath = dirname + os.sep 
#Creamos listas vacias para almacenar las imagenes, el número de directorios y los directorios.
images = []
directories = []
dircount = []
prevRoot=''
cant=0
print("leyendo imagenes de ",imgpath)
for root, dirnames, filenames in os.walk(imgpath):
    for filename in filenames:
        if re.search("\.(png)$", filename):
            cant=cant+1
            filepath = os.path.join(root, filename)
            image = plt.imread(filepath)
            image=cv2.resize(image,(200,200),interpolation = cv2.INTER_AREA)
            image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            images.append(image)
            b = "Leyendo..." + str(cant)
            print (b, end="\r")
            if prevRoot !=root:
                print(root, cant)
                prevRoot=root
                directories.append(root)
                dircount.append(cant)
                cant=0
dircount.append(cant)
dircount = dircount[1:]
dircount[0]=dircount[0]+1
print('Directorios leidos:',len(directories))
print("Imagenes en cada directorio", dircount)
print('suma Total de imagenes en subdirs:',sum(dircount))

#Creamos una lista vacía para indicar las etiquetas
labels=[]
indice=0
for cantidad in dircount:
    for i in range(cantidad):
        labels.append(indice)
    indice=indice+1
print("Cantidad etiquetas creadas: ",len(labels))
import numpy 
tumores=[]
indice=0
for directorio in directories:
    name = directorio.split(os.sep)
    print(indice , name[len(name)-1])
    tumores.append(name[len(name)-1])
    indice=indice+1
y = np.array(labels)
X = np.array(images, dtype=np.uint8) #convierto de lista a numpy
# Encuentra los números únicos de las etiquetas
classes = np.unique(y)
nClasses = len(classes)
print('Total numero de clases : ', nClasses)
print('classes : ', classes)

# 2) EXPLORACION DE DATOS
img = load_img('/content/drive/MyDrive/Data/train/1/2300.png')  
x = img_to_array(img)  # Numpy array con tamaño (3, 500, 500)
x = x.reshape((1,) + x.shape)  #Numpy array con tamaño (1, 3, 500, 500)
# Creamos una funcion en el que transforma la imagen de manera aleatoria y guarda los resultados en la carpeta preview
i = 0
for batch in datagen.flow(x, batch_size=1,
                          save_to_dir='/content/drive/MyDrive/Data/preview', save_prefix='men', save_format='png'):
    i += 1
    if i > 20:
        break

#Visualizamos una imagen después de haber realizado la transformacion
display(Image('/content/drive/MyDrive/Data/preview/men_0_1176.png'))
display(Image('/content/drive/MyDrive/Data/preview/men_0_2130.png'))

# 3) PREPROCESAMIENTO DE DATOS
#Debido al limitado numero de imagenes, utilizaremos la funcion ImageDataGenerator para generar mas imagenes a partir de las que ya tenemos
#De esta manera, nuestro modelo podrá detectar más patrones para poder clasificarlas
datagen = ImageDataGenerator(
        rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest')

# 4) CREACION DEL MODELO
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
import tensorflow as tf
import keras
#Creamos el modelo, bajamos los pixeles de 500 a 200 para bajar el tiempo de procesamiento.
#Como funcion de activacion utilizamos Relu para las capas escondidas y sigmoid para la capa de salida
model = Sequential()
model.add(Conv2D(32, (3, 3), input_shape=(200, 200, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(tf.keras.layers.Flatten(input_shape=(200, 200)))  # Con Flatten convertimos a un vector 1D en vez de 3D
model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(1))
model.add(Activation('softmax'))
#Como es una clasificacion multiclase utilizamos como loss 'categorical_crossentropy'. 
#Como optimizador utilizamos 'rmsprop'
model.compile(loss='categorical_crossentropy',
              optimizer='rmsprop',
              metrics=[keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.SpecificityAtSensitivity(0.5), keras.metrics.SensitivityAtSpecificity(0.5), 'accuracy'])
model.summary()
batch_size = 16

# Esta es la configuración de aumento que usaremos para el entrenamiento
train_datagen = ImageDataGenerator(
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True)

# Esta es la configuración de aumento que usaremos para la validacion
#Los colores de los píxeles tienen valores que van de 0 a 255, haremos una transformación de cada pixel: “valor/255” y nos quedará siempre un valor entre 0 y 1.
test_datagen = ImageDataGenerator(rescale=1./255)

# este es un generador que leerá imágenes encontradas en
# subfolers de 'data / train', y generan indefinidamente
# lotes de datos de imagen aumentados
train_generator = train_datagen.flow_from_directory(
        '/content/drive/MyDrive/Data/train',  # Indicamos el directorio
        target_size=(200, 200),  # Cambiamos el tamaño a 200x200
        batch_size=batch_size,
        class_mode='categorical')  # Nuestra clasificacion es multiple, ya que tenemos 3 clases

# este es un generador similar, para datos de validación
validation_generator = test_datagen.flow_from_directory(
        '/content/drive/MyDrive/Data/validation',
        target_size=(200, 200),
        shuffle = False,
        batch_size=batch_size,
        class_mode='categorical')

#Compilamos el modelo
history=model.fit_generator(
        train_generator,
        steps_per_epoch=1704 // batch_size,
        epochs=100,
        validation_data=validation_generator,
        validation_steps=420 // batch_size)
model.save_weights('modelo.h5')  # Guardamos los pesos despues de realizar el entrenamiento


# 5) ANALISIS DE RESULTADOS

scoreSeg = model.evaluate_generator(validation_generator, 420)
print(scoreSeg)

#Grafico exactitud y perdida vs ciclos.
epochs=100
import matplotlib.pyplot as plt
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs_range = range(epochs)
plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='exactitud entrenamiento')
plt.plot(epochs_range, val_acc, label='exactitud validacion')
plt.legend(loc='lower right')
plt.title('Exactitud en Entrenamiento y validacion')
plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Perdida entrenamiento')
plt.plot(epochs_range, val_loss, label='Perdida validacion')
plt.legend(loc='upper right')
plt.title('Perdida en entrenamiento y valdiacion')
plt.show()
#devuelve la precisión del entrenamiento
print("Precision entrenamiento:"), print(history.history['accuracy'][-1])
print("Precision validacion"), print (history.history['val_accuracy'][-1])

#Grafico sensibilidad y especificidad vs ciclos.
epochs=100
import matplotlib.pyplot as plt
spec = history.history['specificity_at_sensitivity']
val_sens = history.history['sensitivity_at_specificity']
epochs_range = range(epochs)
plt.figure(figsize=(8, 8))
plt.plot(epochs_range, spec, label='especificidad vs sensibilidad ')
plt.plot(epochs_range, val_sens, label='sensibilidad vs especificidad')
plt.legend(loc='upper right')
plt.title('especificidad vs sensibilidad ')
plt.show()
#devuelve la precisión del entrenamiento
print("Exactitud entrenamiento"), print(history.history['specificity_at_sensitivity'][-1])
print("Exactitud validacion"), print(history.history['sensitivity_at_specificity'][-1])

# Matriz de confusión 
import itertools
from sklearn.metrics import confusion_matrix

def make_confusion_matrix(y_true, y_pred, classes = None, figsize = (10, 10),
                          text_size = 15):
  """
  Representa la matriz de confusión resultante del proceso de clasificación binaria
  o multiclase.

  Args:

  y_true: etiqueta real 
  y_pred: predicciones efectuadas por el modelo BINARIZADAS
  classes: Lista de clases
  figsize: tupla que indica dimensiones de la matriz (base, altura)
  text_size: Tamaño de la fuente en la matriz de confusión
  """

  cm = confusion_matrix(y_true, y_pred)
  cm_norm = cm.astype('float') / cm.sum(axis = 1) [:, np.newaxis]
  n_classes = cm.shape[0]
  
  fig, ax = plt.subplots(figsize = figsize)
  cax = ax.matshow(cm, cmap = plt.cm.Blues)
  fig.colorbar(cax)

  if classes:
    labels = classes
  else:
    labels = np.arange(cm.shape[0])

  ax.set(title = 'Matriz de Confusión',
         xlabel = 'Etiqueta Predicha',
         ylabel = 'Etiqueta Real',
         xticks = np.arange(n_classes),
         
         yticks = np.arange(n_classes),
         xticklabels = labels,
         yticklabels = labels)
  
  ax.xaxis.set_label_position('bottom')
  ax.xaxis.tick_bottom()

  threshold = (cm.max() + cm.min()) /2.

  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
    plt.text(j, i, f'{cm[i, j]} ({cm_norm[i, j]*100:.1f})%',
             horizontalalignment = 'center', 
             color = 'white' if cm[i, j] > threshold else 'black', 
             size = text_size)

y_pred = model.predict(validation_generator)
import numpy as np
y_pred=np.argmax(y_pred, axis=1)
y_pred[1]
y_true = validation_generator.classes
make_confusion_matrix(y_true, y_pred, classes = ['Meniongina','Glioma','Pituitario'], figsize = (10, 10), text_size = 15)

# 6) APLICACION FLASK

model.save('/content/drive/MyDrive/flask/model.hdf5')

!mkdir -p /drive/ngrok-ssh
# %cd /drive/ngrok-ssh
!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip -O ngrok-stable-linux-amd64.zip
!unzip -u ngrok-stable-linux-amd64.zip
!cp /drive/ngrok-ssh/ngrok /ngrok
!chmod +x /ngrok

!/ngrok authtoken 22DtvGEHks2xlQn8Jp6aIqxAwaV_2hTjrAzSWDZMb596oNxkJ

from flask import Flask 
from flask_ngrok import run_with_ngrok 
app2 = Flask(__name__) 
run_with_ngrok(app2)    
  
@app.route("/") 
def home(): 
    return "<h1>Clasificación de imágenes de cáncer de cerebro mediante aprendizaje profundo</h1>"
    
app2.run()
